== Tile format

Tiles are built using the GeoJSON specification.

They're built in two phases, though, because it takes a long time to generate GeoJSON data, even after optimization.

=== Phase 1: GeoJSON data, UTFGrid

See GeoJSON 1.0: http://geojson.org/geojson-spec.html
See UTFGrid 1.2 spec (as of 2012-01-11): https://github.com/mapbox/utfgrid-spec/blob/master/1.2/utfgrid.md

A tile looks like this:

{
  "type": "FeatureCollection", /* GeoJSON */
  "features": [ /* GeoJSON */
    {
      "type": "Feature",
      "geometry": ...GeoJSON geometry...
      "id": "DisseminationArea-12314",
      "properties": {
        "uid": "12314",
        "type": "DisseminationArea",
        "name": "Statistics Canada-supplied name",
        "statistics": {
          "2011": {
            "Population": {
              "value": 4123,
              "note": "This number is totally correct"
            }
          },
          ...more statistics...
        }
      }
    },
    ...more features...
  ],
  "utfgrids": [ /* Not banned by the GeoJSON spec */
    {
      "grid": ["...", "...", ... ], /* UTFGrid */
      "keys": [ "", "Province-11", "ElectoralDistrict-132", ... ] /* UTFGrid */
    }
  ]
}

The GeoJSON contains all data necessary. UTFGrid data is entirely redundant.

We generate UTFGrid data by actually rendering the tiles onto in-memory SVGs
during creation. The benefit: the browser can quickly look up a GeoJSON
feature based on a pixel location.

Why is it a *list* of UTFGrids? Because there's no other way to transmit
partial hierarchies. For instance, if a Tract and Subdivision are in the
same spot, they're shown Tract-on-top-of-Subdivision on the map. But the
Subdivision isn't a parent of the Tract. The only way for the client to
see both (aside from actual hit-detection on vector data) is to transmit
two distinct hierarchies.

We mass-render into the "utfgrids" and "tile_features" tables. Both are keyed
by (zoom_level, tile_row, tile_column), which are standard across mapping
platforms. The latter table is also keyed by region ID and contains all the
properties we need. You can imagine, then, for a given tile, how we populate
the "utfgrids" column (a single SQL cell) and the "features" list (each entry
corresponds to an SQL row).

We do not render "statistics" in this phase. We postpone that to the last
possible instant, because we need to pre-process everything we can. That way,
when new statistics come out we can publish them much more quickly.

==== Implementation

1. Import regions from StatsCan data into the database.
2. From those regions, extract polygons. (script/preprocess-polygons.sql)
3. Decide which polygons to render at which zoom levels. (script/preprocess-polygons.sql)
4. Render them into region_polygon_tiles. (tile_renderer/render_region_polygon_tiles.py)
5. From region_polygon_tiles, render UTFGrids. (script/preprocess-utfgrids.sql, tile_renderer/render_utfgrids.py)
6. From region_polygon_tiles, render feature_tiles. (script/process-features.sql -- no Python needed)

Generally, straight SQL is much faster than Python because it works on all
its source data in bulk, instead of a row at a time. We only use Python where
it makes more sense:

1. Slicing a polygon into tiles: there's no good way in SQL to slice the way we do.
2. Rendering UTFGrids: we render SVG to an image buffer; SQL doesn't do that.

=== Phase 2: Statistics

We render a table of region_id -> statistics, which looks like the "statistics"
section in the GeoJSON tile description above. It's straightforward to generate
this: just loop over indicator_region_values, group by region and year, and
encode as JSON.

This is in ./render_statistics.py

=== Phase 3: Merge

For a given tile:

1. Select the UTFGrid JSON (an Array) from "utfgrids".
2. Select the features from "feature_tiles".
3. With the region IDs from step 2, select statistics from "statistics".
4. Create the "features" JSON Array using the results from steps 2 and 3.
5. Create the entire JSON tile through string concatenation.

There's no need for decoding and encoding JSON. The whole thing could
conceivably be done using SQL. (Why *not* merge as SQL? Because we merge on
the fly. Otherwise we'd be stuck with an 8GB database on our development
machine that we need to move to our servers. That would be too slow.)
